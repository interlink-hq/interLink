---
sidebar_position: 1
---
import ThemedImage from '@theme/ThemedImage';
import useBaseUrl from '@docusaurus/useBaseUrl';

# Introduction

[![GitHub License](https://img.shields.io/github/license/intertwin-eu/interlink)](https://img.shields.io/github/license/intertwin-eu/interlink)
![GitHub Repo stars](https://img.shields.io/github/stars/intertwin-eu/interlink)

![GitHub Release](https://img.shields.io/github/v/release/intertwin-eu/interlink)
![Tested with Dagger](https://img.shields.io/badge/tested_with_dagger-v0.13.3-green)
[![Go Report Card](https://goreportcard.com/badge/github.com/intertwin-eu/interlink)](https://goreportcard.com/report/github.com/intertwin-eu/interlink)

[![Slack server](https://img.shields.io/badge/slack_server-8A2BE2?link=https%3A%2F%2Fjoin.slack.com%2Ft%2Fintertwin%2Fshared_invite%2Fzt-2cs67h9wz-2DFQ6EiSQGS1vlbbbJHctA)](https://join.slack.com/t/intertwin/shared_invite/zt-2cs67h9wz-2DFQ6EiSQGS1vlbbbJHctA)


:::warning

interLink is in early development phase, thus subject to breaking changes with no guarantee of backward compatibility.

:::

InterLink is a Kubernetes plugin that enables the offloading of containers to 
remote systems. 

It is designed to extend the capabilities of Kubernetes clusters by allowing 
pods to run on external resources, such as high-performance computing (HPC) systems, 
remote Kubernetes clusters, or serverless computing services. 

InterLink provides a flexible and scalable way to distribute workloads across 
different environments, optimizing resource utilization and performance.


## Overview

InterLink necessary needs a Kubernetes cluster to run on, this cluster will be 
considered the "local" cluster.
The "remote" system can be another Kubernetes cluster, an HPC system, or a 
serverless computing service.
The remote system will be running a plugin that will define how the containers 
will run on the remote system.

The containers being offloaded are batch (or "job") containers with a predefined 
lifecycle and are non-interactive (see [Targets](#targets)). 
Dispatching to the remote system is achieved through a combination of 
[Virtual Kubelets](https://virtual-kubelet.io/), interLink's API, and plugins. 
These plugins define how the containers will run on the remote system 
(see [Target providers](#target-providers)).

The InterLink API and plugins can be deployed in three different configurations 
across the local cluster and the remote system:

- Both deployed remotely (**[Edge-node](#edge-node)**)
- Both deployed locally (**[In-cluster](#in-cluster)**)
- API local, plugin remote (**[Tunneled](#tunneled)**)


```
+---------------------------+  +----------------------------+
| Virtual Node              |  |     Pod Containers Runtime |
|                           |  |                            |
|                           |  |                            |
|                           |  |                            |
|        +-----------------------------------------+        |
|        | (API + plugin) interLink                |        |
|        |          (API) interLink (plugin)       |        |
|        |                interLink (API + plugin) |        |
|        +-----------------------------------------+        |
|                           |  |                            |
|                           |  |                            |
|                           |  |                            |
|                           |  |                            |
|                           |  |                            |
|                           |  |                            |
+---------------------------+  +----------------------------+
```



## Targets
> rename to Applications

- __K8s applications with tasks to be executed on HPC systems__: This target focuses on Kubernetes applications that require high-performance computing (HPC) resources for executing tasks. These tasks might involve complex computations, simulations, or data processing that benefit from the specialized hardware and optimized performance of HPC systems.

- __Remote "runner"-like application for heavy payload execution requiring GPUs__: This target is designed for applications that need to execute heavy computational payloads, particularly those requiring GPU resources. These applications can be run remotely, leveraging powerful GPU hardware to handle tasks such as machine learning model training, data analysis, or rendering.

- __Lambda-like functions calling on external resources__: This target involves running containers on demand with specific computing needs. Now these resources might also be outside of the Kubernetes cluster thanks to interLink functionality.

## Target providers
> rename to Runtime providers

Our solution is designed to target a wide range of providers with container execution capabilities, including but not limited to:

- __SLURM or HTCondor batch systems with Apptainer, Enroot, or Singularity__: These batch systems are widely used in high-performance computing environments to manage and schedule jobs. By integrating with container runtimes like Apptainer, Enroot, or Singularity, our solution can efficiently execute containerized tasks on these systems.
- __On-demand virtual machines with any container runtime__: This includes virtual machines that can be provisioned on-demand and support container runtimes such as Docker, Podman, or others. This flexibility allows for scalable and dynamic resource allocation based on workload requirements.
- __Remote Kubernetes clusters__: Our solution can extend the capabilities of existing Kubernetes clusters, enabling them to offload workloads to another remote cluster. This is particularly useful for distributing workloads across multiple clusters for better resource utilization and fault tolerance.
- __Lambda-like services__: These are serverless computing services that execute code in response to events and automatically manage the underlying compute resources. By targeting these services, our solution can leverage the scalability and efficiency of serverless architectures for containerized workloads. All of this, while exposing a bare Kubernetes API kind of orchestration.

## NOT a target
> rename to non an application

- __Long-running services__: Our solution is not designed for services that need to run continuously for extended periods. It is optimized for tasks that have a defined start and end, rather than persistent services exposing intra-cluster communication endpoints.
- __Kubernetes Federation__: We do not aim to support Kubernetes Federation, which involves managing multiple Kubernetes clusters as a single entity. Our focus is on enabling Kubernetes pods to execute on remote resources, not on federating all kind of resources on multiple clusters.


## Deployment scenarios

### Edge-node

In this scenario, the Virtual Kubelet communicates with remote services deployed on a dedicate edge node exposing authenticated interLink APIs and its associated plugin. This setup is ideal for scenarios where edge computing resources are utilized for controlled communication b/w the Kubernetes cluster and the remote resources.

<ThemedImage 
        alt="Docusaurus themed image"
        sources={{
          light: useBaseUrl('/img/scenario-1_light.svg'),
          dark: useBaseUrl('/img/scenario-1_dark.svg'),
        }}
/>

### In-cluster

This scenario involves deploying a Virtual Kubelet along with the interLink API server and the plugin to interact with a remote API. This setup allows Kubernetes pods to be executed on remote resources while all other components sits inside the Kubernetes cluster.

<ThemedImage 
        alt="Docusaurus themed image"
        sources={{
          light: useBaseUrl('/img/scenario-2_light.svg'),
          dark: useBaseUrl('/img/scenario-2_dark.svg'),
        }}
/>

### Tunneled

This deployment involves the Virtual Kubelet connecting to a remote interLink API server and its plugin through a secure tunnel. This setup ensures secure communication between the Kubernetes cluster and the remote resources, making it suitable for environments with strict security requirements or to host services on a multi user host like a login node.

<ThemedImage 
        alt="Docusaurus themed image"
        sources={{
          light: useBaseUrl('/img/scenario-3_light.svg'),
          dark: useBaseUrl('/img/scenario-3_dark.svg'),
        }}
/>

For more information visit the [architecture page](arch)

